# === speech_tts.py ===
import threading
import azure.cognitiveservices.speech as speechsdk
from config import AZURE_SPEECH_KEY, AZURE_REGION
import os

# --- Singleton Synthesizer Initialization ---
try:
    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_REGION)
    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
    print("[Azure TTS] Synthesizer initialized.")
except Exception as e:
    synthesizer = None
    print("[Azure TTS] Initialization failed:", e)

# === Flag Î³Î¹Î± Î­Î»ÎµÎ³Ï‡Î¿ Ï†Ï‰Î½Î®Ï‚ ===
is_speaking = False


def clean_gesture_marker(ssml_text):
    """
    Î‘Î½ Ï„Î¿ SSML Ï€ÎµÏÎ¹Î­Ï‡ÎµÎ¹ 'R<' Î® 'L<' (Î±ÎºÏŒÎ¼Î± ÎºÎ¹ Î±Î½ ÎµÎ¯Î½Î±Î¹ Î¼Î­ÏƒÎ± ÏƒÏ„Î¿ SSML), 
    Î±Ï†Î±Î¹ÏÎµÎ¯ Ï„Î¿ Î³ÏÎ¬Î¼Î¼Î± ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ (ssml, gesture).
    Î•Ï€Î¯ÏƒÎ·Ï‚ ÎºÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ stray 'L' Î® 'R' Ï€Î¿Ï… Î²ÏÎ¯ÏƒÎºÎ¿Î½Ï„Î±Î¹ ÏƒÎµ Î»Î¬Î¸Î¿Ï‚ Î¸Î­ÏƒÎ·.
    """
    s = ssml_text.strip()

    # --- Î‘Î½ Ï„Î¿ Î³ÏÎ¬Î¼Î¼Î± ÎµÎ¯Î½Î±Î¹ Î¼Î­ÏƒÎ± ÏƒÏ„Î¿ SSML (Ï€.Ï‡. "L\n <speak>")
    if "\nL" in s or "L\n" in s or "L <" in s or "L<" in s:
        s = s.replace("L", "", 1)
        return s.strip(), "L"

    if "\nR" in s or "R\n" in s or "R <" in s or "R<" in s:
        s = s.replace("R", "", 1)
        return s.strip(), "R"

    # --- Î‘Î½ Ï„Î¿ Î³ÏÎ¬Î¼Î¼Î± ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î·Î½ Î±ÏÏ‡Î® (ÏƒÏ‰ÏƒÏ„Î® Ï€ÎµÏÎ¯Ï€Ï„Ï‰ÏƒÎ·)
    if s.startswith("R<"):
        cleaned = s.replace("R<", "<", 1)
        return cleaned.strip(), "R"
    if s.startswith("L<"):
        cleaned = s.replace("L<", "<", 1)
        return cleaned.strip(), "L"

    # --- Î‘Î½ Ï„Î¿ Î³ÏÎ¬Î¼Î¼Î± ÎµÎ¯Î½Î±Î¹ ÏƒÏ„Î¿ Ï„Î­Î»Î¿Ï‚ (Ï€.Ï‡. "</speak>L")
    if s.endswith("L"):
        return s[:-1].strip(), "L"
    if s.endswith("R"):
        return s[:-1].strip(), "R"

    return s, None


def speak_with_azure_tts(ssml_text, visualizer):
    def _speak():
        import time
        global is_speaking

        try:
            if synthesizer is None:
                print("[Azure TTS] Synthesizer not available!")
                visualizer.stop_speaking()
                return

            # === Î‘Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Î¹ÎºÏÎ¿Ï†ÏÎ½Î¿Ï… Ï€ÏÎ¹Î½ Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹ Î· ÎµÎºÏ†ÏÎ½Î·ÏƒÎ· ===
            os.system("amixer set Capture nocap")

            # ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ SSML ÎºÎ±Î¹ ÎµÏÏÎµÏƒÎ· gesture marker
            ssml_clean, gesture = clean_gesture_marker(ssml_text)
            if gesture:
                print(f"ğŸ¤– Gesture marker found: {gesture} (will run after TTS)")

            is_speaking = True
            visualizer.start_speaking()
            print("ğŸ”ˆ [TTS] ÎœÎ¹Î»Î¬ÎµÎ¹ Ï„ÏÏÎ±...")
            tts_start = time.time()
            result_future = synthesizer.speak_ssml_async(ssml_clean)

            def check_done():
                global is_speaking
                result = result_future.get()
                tts_time = time.time() - tts_start

                if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                    print(f"âœ… [TTS] Î¤ÎµÎ»ÎµÎ¯Ï‰ÏƒÎµ Î· ÎµÎºÏ†ÏÎ½Î·ÏƒÎ·. â±ï¸ {tts_time:.2f}s")

                    # === Î•ÎºÏ„Î­Î»ÎµÏƒÎ· gesture ÎœÎ•Î¤Î‘ Ï„Î¿ TTS ===
                    if gesture == "R":
                        print("ğŸ–ï¸ Î•ÎºÏ„ÎµÎ»ÎµÎ¯ gesture: Î´ÎµÎ¾Î¯ Ï‡Î­ÏÎ¹ (R)")
                        try:
                            from arduino_control import wave_right_hand
                            wave_right_hand()
                        except Exception as e:
                            print("âš ï¸ Gesture error:", e)

                    elif gesture == "L":
                        print("ğŸ‘ˆ Î•ÎºÏ„ÎµÎ»ÎµÎ¯ gesture: Î±ÏÎ¹ÏƒÏ„ÎµÏÏŒ Ï‡Î­ÏÎ¹ (L)")
                        try:
                            from arduino_control import wave_left_hand
                            wave_left_hand()
                        except Exception as e:
                            print("âš ï¸ Gesture error:", e)

                elif result.reason == speechsdk.ResultReason.Canceled:
                    print("âŒ [TTS] Î‘ÎºÏ…ÏÏÎ¸Î·ÎºÎµ:", result.cancellation_details.reason)
                    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· ÎµÏ…Î³ÎµÎ½Î¹ÎºÎ¿Ï fallback Î¼Î·Î½ÏÎ¼Î±Ï„Î¿Ï‚
                    fallback = (
                        "<speak version=\"1.0\" xmlns:mstts=\"https://www.w3.org/2001/mstts\" xml:lang=\"el-GR\">"
                        "<voice name=\"el-GR-NestorasNeural\">"
                        "<mstts:express-as style=\"chat\">"
                        "<prosody rate=\"0.85\" pitch=\"+2.2st\">"
                        "ÎœÏ€Î¿ÏÎµÎ¯Ï„Îµ Î½Î± ÎµÏ€Î±Î½Î±Î»Î¬Î²ÎµÏ„Îµ Ï€Î±ÏÎ±ÎºÎ±Î»Ï;"
                        "</prosody>"
                        "</mstts:express-as>"
                        "</voice>"
                        "</speak>"
                    )
                    try:
                        print("ğŸ” [TTS] Î Î±Î¯Î¶ÎµÎ¹ fallback Î¼Î®Î½Ï…Î¼Î± (ÎµÏ€Î±Î½Î¬Î»Î·ÏˆÎ·)...")
                        synthesizer.speak_ssml_async(fallback).get()
                    except Exception as e:
                        print("âš ï¸ Fallback error:", e)

                time.sleep(0.2)
                visualizer.stop_speaking()
                is_speaking = False

                # === Î•Ï€Î±Î½ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î¼Î¹ÎºÏÎ¿Ï†ÏÎ½Î¿Ï… ===
                os.system("amixer set Capture cap")

            threading.Thread(target=check_done, daemon=True).start()

        except Exception as e:
            print("âš ï¸ Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ Azure TTS:", e)
            visualizer.stop_speaking()
            is_speaking = False
            os.system("amixer set Capture cap")  # Î±ÏƒÏ†Î¬Î»ÎµÎ¹Î±: ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î¾Î±Î½Î¬ Ï„Î¿ mic

    threading.Thread(target=_speak, daemon=True).start()
