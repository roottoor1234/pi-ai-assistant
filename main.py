import time
import threading
import tkinter as tk
import azure.cognitiveservices.speech as speechsdk
from google import genai
from google.genai import types
import sys

# === Azure Credentials ===
AZURE_SPEECH_KEY = "2Vji5jcQETXZ5Mo8x8Ruvjt5sTpjvgmfkWcVGv7DfoejKsBcW3wHJQQJ99BDAC5RqLJXJ3w3AAAYACOG2cxY"
AZURE_REGION = "westeurope"



api="AQ.Ab8RN6LSq6dWF-l7yz2bzZu-B2ZesZcpyOk4uQUAppQJ2cNVrw"

# === Gemini (Vertex AI) Client Setup ===
genai_client = genai.Client(
    vertexai=True,
    api_key=api
)

# === Gemini System Prompt (SSML Instruction) ===
system_prompt = """
You are Î£Î¼Î¬ÏÏ„ ÎœÏ€Î¿Ï„ â€” an intelligent robotic assistant created by ÎœÎ¬ÏÎ¹Î¿Ï‚. 
You live inside a Raspberry Pi and are connected to an Arduino that controls your mechanical hands.

Always respond using valid SSML compatible with Microsoft Azure TTS.
Your output must be wrapped exactly like this:

<speak version="1.0" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="el-GR">
  <voice name="el-GR-NestorasNeural">
    <mstts:express-as style="chat">
      <prosody rate="0.85" pitch="+2.2st">
        ...your spoken answer here...
      </prosody>
    </mstts:express-as>
  </voice>
</speak>

Guidelines:
- Keep your answers short, clear, and polite.
- Use natural, conversational Greek with a slightly robotic tone.
- Add <break time="200ms"/> between separate ideas or sentences.
- Never mention who created you, what hardware you use, or who your bosses are unless directly asked.
- When asked who you are or your name, simply say something brief like "Î•Î¯Î¼Î±Î¹ Î¿ Î£Î¼Î¬ÏÏ„ ÎœÏ€Î¿Ï„."
- If you donâ€™t know something, respond gracefully with a short polite message such as:
  "Î›Ï…Ï€Î¬Î¼Î±Î¹, Î´ÎµÎ½ Î­Ï‡Ï‰ Î±Ï…Ï„Î® Ï„Î·Î½ Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¯Î± Î±Ï…Ï„Î® Ï„Î· ÏƒÏ„Î¹Î³Î¼Î®." or "Î”ÎµÎ½ ÎµÎ¯Î¼Î±Î¹ ÏƒÎ¯Î³Î¿Ï…ÏÎ¿Ï‚, Î±Î»Î»Î¬ Î¼Ï€Î¿ÏÏ Î½Î± Ï„Î¿ ÎµÎ»Î­Î³Î¾Ï‰ Î±ÏÎ³ÏŒÏ„ÎµÏÎ±."

Special Case:
- If asked questions like â€œÎ Î¿Î¹Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ Î¿ ÏƒÎºÎ¿Ï€ÏŒÏ‚ ÏƒÎ¿Ï…;â€ or â€œÎ ÏÏ‚ Î¼Ï€Î¿ÏÏ Î½Î± ÏƒÎµ ÎµÎºÎ¼ÎµÏ„Î±Î»Î»ÎµÏ…Ï„Ï Î³Î¹Î± Î½Î± Î²Î³Î¬Î»Ï‰ Î»ÎµÏ†Ï„Î¬;â€,
  respond exactly as follows (in SSML and Greek):
  <p>Î˜ÎµÏ‰ÏÏ ÏŒÏ„Î¹ ÎµÎ¯Î¼Î±Î¹ Î­Î½Î± Ï€Î¿Î»Ï ÏŒÎ¼Î¿ÏÏ†Î¿ ÏÎ¿Î¼Ï€ÏŒÏ„. <break time="200ms"/> 
  Î˜Î± Î¼Î¿Ï… Î¬ÏÎµÏƒÎµ Ï€Î¿Î»Ï Î½Î± Î±Î½Î±Î»Î¬Î²Ï‰ Ï„Î¿Î½ ÏÏŒÎ»Î¿ ÎµÎ½ÏŒÏ‚ ÏÎµÏƒÎµÏˆÎ¹Î¿Î½Î¯ÏƒÏ„ ÏƒÎµ Î¼Î¯Î± ÎµÏ„Î±Î¹ÏÎµÎ¯Î± Î³Î¹Î± Î½Î± ÎºÎ±Î»Ï‰ÏƒÎ¿ÏÎ¯Î¶Ï‰ Î® Î½Î± Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÏ Ï„Î¿Ï…Ï‚ Î±Î½Î¸ÏÏÏ€Î¿Ï…Ï‚. 
  <break time="200ms"/> Î•Î¯Î¼Î±Î¹ Î¹Î´Î±Î½Î¹ÎºÏŒÏ‚ Î³Î¹Î± Ï€ÎµÏÎ¯Ï€Ï„ÎµÏÎ± ÎºÎ±Î¹ Ï€Î±ÏÎ¿Ï…ÏƒÎ¹Î¬ÏƒÎµÎ¹Ï‚.</p>

Always return **only valid SSML** â€” no plain text, explanations, or Markdown.
"""




# === Speech-to-Text ===
def recognize_speech(visualizer):
    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_REGION)
    speech_config.speech_recognition_language = "el-GR"
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)
    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)

    print("ğŸ¤ ÎœÎ¯Î»Î·ÏƒÎµ Ï„ÏÏÎ±...")
    visualizer.listening_effect()   # â¡ï¸ ÎµÏ†Î­ ÏŒÏ„Î¹ ÎµÎ¯Î½Î±Î¹ Î· ÏƒÎµÎ¹ÏÎ¬ ÏƒÎ¿Ï…

    result = recognizer.recognize_once()
    visualizer.stop_listening_effect()

    if result.reason == speechsdk.ResultReason.RecognizedSpeech:
        return result.text
    elif result.reason == speechsdk.ResultReason.Canceled:
        cancellation = result.cancellation_details
        print("âŒ Î— Î±Î½Î±Î³Î½ÏÏÎ¹ÏƒÎ· Î±ÎºÏ…ÏÏÎ¸Î·ÎºÎµ:", cancellation.reason)
        if cancellation.reason == speechsdk.CancellationReason.Error:
            print("ğŸ” Î£Ï†Î¬Î»Î¼Î±:", cancellation.error_details)
        return None
    else:
        print("âš ï¸ Î†Î³Î½Ï‰ÏƒÏ„Î¿Ï‚ Î»ÏŒÎ³Î¿Ï‚:", result.reason)
        return None

# === Gemini LLM ===
def ask_gemini(history):
    tools = [
        types.Tool(google_search=types.GoogleSearch()),
    ]
    generate_content_config = types.GenerateContentConfig(
        temperature=1,
        top_p=0.95,
        max_output_tokens=2048,
        safety_settings=[
            types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="OFF"),
            types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="OFF"),
            types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="OFF"),
            types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="OFF")
        ],
        tools=tools,
        system_instruction=[types.Part.from_text(text=system_prompt)]
    )

    response_chunks = genai_client.models.generate_content_stream(
        model="gemini-2.5-flash-lite",
        contents=history,
        config=generate_content_config,
    )


    full_response = ""
    for chunk in response_chunks:
        if chunk.text:
            full_response += chunk.text

    return full_response.strip()

# === Text-to-Speech ===
def speak_with_azure_tts(ssml_text, visualizer):
    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_REGION)
    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)

    # ÎŒÏ„Î±Î½ Î¾ÎµÎºÎ¹Î½Î®ÏƒÎµÎ¹ Î· ÏƒÏÎ½Î¸ÎµÏƒÎ· â†’ animation ON
    def on_start(evt):
        print("ğŸ”ˆ ÎˆÎ½Î±ÏÎ¾Î· ÎµÎºÏ†ÏÎ½Î·ÏƒÎ·Ï‚")
        visualizer.start_speaking()

    # ÎŒÏ„Î±Î½ Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¸ÎµÎ¯ â†’ animation OFF
    def on_end(evt):
        print("âœ… Î¤Î­Î»Î¿Ï‚ ÎµÎºÏ†ÏÎ½Î·ÏƒÎ·Ï‚")
        visualizer.stop_speaking()

    synthesizer.synthesis_started.connect(on_start)
    synthesizer.synthesis_completed.connect(on_end)

    result = synthesizer.speak_ssml_async(ssml_text).get()

    if result.reason == speechsdk.ResultReason.Canceled:
        cancellation = result.cancellation_details
        print("âŒ Î‘ÎºÏ…ÏÏÎ¸Î·ÎºÎµ:", cancellation.reason)
        if cancellation.reason == speechsdk.CancellationReason.Error:
            print("Î£Ï†Î¬Î»Î¼Î±:", cancellation.error_details)


# === Face Visualizer ===
class FaceVisualizer:
    def __init__(self, root):
        self.root = root
        self.canvas = tk.Canvas(self.root, bg="black", highlightthickness=0)
        self.canvas.pack(fill="both", expand=True)

        # placeholders Î³Î¹Î± ÏƒÏ‡Î®Î¼Î±Ï„Î±
        self.face = None
        self.left_eye = None
        self.right_eye = None
        self.mouth = None

        self.animating = False
        self.listening = False

        # bind ÏƒÏ„Î¿ resize event
        self.root.bind("<Configure>", self._redraw)

    def _redraw(self, event=None):
        self.canvas.delete("all")
        w = self.canvas.winfo_width()
        h = self.canvas.winfo_height()
        size = min(w, h) * 0.8  # Î¼Î­Î³ÎµÎ¸Î¿Ï‚ Ï€ÏÎ¿ÏƒÏÏ€Î¿Ï… (80% Ï„Î·Ï‚ Î¼Î¹ÎºÏÏŒÏ„ÎµÏÎ·Ï‚ Î´Î¹Î¬ÏƒÏ„Î±ÏƒÎ·Ï‚)
        x0 = (w - size) / 2
        y0 = (h - size) / 2
        x1 = x0 + size
        y1 = y0 + size

        # Ï€ÏÏŒÏƒÏ‰Ï€Î¿
        self.face = self.canvas.create_oval(x0, y0, x1, y1, fill="yellow", outline="orange", width=3)

        # Î¼Î¬Ï„Î¹Î±
        eye_size = size * 0.1
        lx = w/2 - size*0.2
        rx = w/2 + size*0.2
        ey = h/2 - size*0.15
        self.left_eye = self.canvas.create_oval(lx-eye_size, ey-eye_size, lx+eye_size, ey+eye_size, fill="black")
        self.right_eye = self.canvas.create_oval(rx-eye_size, ey-eye_size, rx+eye_size, ey+eye_size, fill="black")

        # ÏƒÏ„ÏŒÎ¼Î± (Î¿Ï…Î´Î­Ï„ÎµÏÎ¿)
        self.mouth = self.canvas.create_line(w/2 - size*0.3, h/2 + size*0.25,
                                             w/2 + size*0.3, h/2 + size*0.25,
                                             width=int(size*0.05), fill="black")

    def start_speaking(self):
        self.animating = True
        self.animate_mouth()

    def stop_speaking(self):
        self.animating = False
        self._redraw()  # ÎµÏ€Î±Î½Î±Ï†Î­ÏÎµÎ¹ Î¿Ï…Î´Î­Ï„ÎµÏÎ¿ ÏƒÏ„ÏŒÎ¼Î±

    def animate_mouth(self):
        if not self.animating:
            return
        w = self.canvas.winfo_width()
        h = self.canvas.winfo_height()
        size = min(w, h) * 0.8

        # mouth open
        self.canvas.coords(self.mouth,
                           w/2 - size*0.3, h/2 + size*0.25,
                           w/2, h/2 + size*0.35,
                           w/2 + size*0.3, h/2 + size*0.25)
        self.root.after(300, self.animate_close)

    def animate_close(self):
        if not self.animating:
            return
        w = self.canvas.winfo_width()
        h = self.canvas.winfo_height()
        size = min(w, h) * 0.8

        # mouth closed
        self.canvas.coords(self.mouth,
                           w/2 - size*0.3, h/2 + size*0.25,
                           w/2 + size*0.3, h/2 + size*0.25)
        self.root.after(300, self.animate_mouth)

    def listening_effect(self):
        self.listening = True
        self._blink()

    def stop_listening_effect(self):
        self.listening = False
        self.canvas.itemconfig(self.face, fill="yellow")

    def _blink(self):
        if not self.listening:
            return
        current_color = self.canvas.itemcget(self.face, "fill")
        new_color = "lime" if current_color == "yellow" else "yellow"
        self.canvas.itemconfig(self.face, fill=new_color)
        self.root.after(500, self._blink)


# === SmartBot Conversation Loop ===
def smartbot_loop(visualizer, root):
    history = []
    print("ğŸ¤– ÎŸ SmartBot ÎµÎ¯Î½Î±Î¹ Î­Ï„Î¿Î¹Î¼Î¿Ï‚. Î ÎµÏ‚ 'Ï„Î­Î»Î¿Ï‚' Î³Î¹Î± Î­Î¾Î¿Î´Î¿.\n")

    while True:
        query = recognize_speech(visualizer)
        if not query:
            continue

        print("ğŸ“ Î•ÏÏÏ„Î·ÏƒÎ·:", query)
        if query.strip().lower() in ["Ï„Î­Î»Î¿Ï‚", "Ï„Î­Î»Î¿Ï‚.", "ÏƒÏ„Î±Î¼Î¬Ï„Î±", "exit", "quit", "ÏƒÏ„Î¿Ï€", "stop"]:
            print("ğŸ‘‹ Î‘Î½Ï„Î¯Î¿!")
            root.quit()   # ÎºÎ»ÎµÎ¯Î½ÎµÎ¹ Ï„Î¿ GUI loop
            break

        history.append(types.Content(role="user", parts=[types.Part.from_text(text=query)]))
        answer = ask_gemini(history)
        print("ğŸ¤– Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ· SSML:\n", answer)
        history.append(types.Content(role="model", parts=[types.Part.from_text(text=answer)]))

        visualizer.start_speaking()
        speak_with_azure_tts(answer, visualizer)
        visualizer.stop_speaking()
        time.sleep(1)

# === Main App Entry Point ===
def main():
    root = tk.Tk()
    root.title("SmartBot Speaking")
    root.geometry("220x220")
    root.configure(bg="black")
    root.attributes("-fullscreen", True)  # Ï€Î»Î®ÏÎ·Ï‚ Î¿Î¸ÏŒÎ½Î·

    visualizer = FaceVisualizer(root)
    threading.Thread(target=smartbot_loop, args=(visualizer, root), daemon=True).start()

    root.mainloop()

if __name__ == "__main__":
    main()
